{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7534de59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hadyo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hadyo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\hadyo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore', category = DeprecationWarning)\n",
    "import requests\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from urllib import request\n",
    "from random import randint\n",
    "#from wordcloud import WordCloud\n",
    "from nltk import word_tokenize\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import gensim\n",
    "from gensim.models import LdaModel, Word2Vec\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn import preprocessing\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "#!pip install mlxtend\n",
    "#from mlxtend.evaluate import bias_variance_decomp\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection  import cross_val_score\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, confusion_matrix, plot_confusion_matrix\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2111929b",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_url_list = [\"https://www.gutenberg.org/files/19719/19719-0.txt\",\n",
    "                  \"https://www.gutenberg.org/cache/epub/28434/pg28434.txt\",\n",
    "                  \"https://www.gutenberg.org/cache/epub/15147/pg15147.txt\",\n",
    "                  \"https://www.gutenberg.org/cache/epub/17866/pg17866.txt\",\n",
    "                  \"https://www.gutenberg.org/files/3772/3772-0.txt\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccffe308",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81fb2497",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#function read raw data\n",
    "def read_books(url):\n",
    "    files = []\n",
    "    for i in url:\n",
    "        file = requests.get(url = i)\n",
    "        files.append(file.content.decode('utf-8'))\n",
    "    return files\n",
    "\n",
    "#read raw data\n",
    "raw_dataset = read_books(books_url_list)\n",
    "len(raw_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92462147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Function cleaned tokens\n",
    "def cleaned_text(raw_text):\n",
    "    text_beg = raw_text.find(\"*** START OF\")\n",
    "    text_end = raw_text.find(\"*** END OF\")\n",
    "\n",
    "    raw_text = raw_text[text_beg : text_end]\n",
    "    raw_text = re.findall(r\"[a-zA-Z]+\", raw_text)\n",
    "    raw_text = \" \".join(raw_text).lower()\n",
    "    tokens = word_tokenize(raw_text)\n",
    "    stop_words = stopwords.words(\"english\")\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens if token not in stop_words]\n",
    "    \n",
    "    return tokens\n",
    "#Getting cleaned tokens\n",
    "tokens = []\n",
    "for i in range(len(raw_dataset)):\n",
    "    tokens.append(cleaned_text(raw_dataset[i]))\n",
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33c10298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "5\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "#function to extract author name, book name and labels\n",
    "book_author_mapping = {}\n",
    "def extract_book_author(raw_text, index):\n",
    "    label = chr(index + 97)\n",
    "        \n",
    "    title_beg = raw_text.find(\"Title\") + 7\n",
    "    title_end = raw_text.find(\"\\r\\n\\r\\nAuthor\")\n",
    "    title = raw_text[title_beg : title_end]\n",
    "\n",
    "    author_beg = raw_text.find(\"Author\") + 8\n",
    "    c = 0\n",
    "    while raw_text[author_beg + c] != \"\\r\":\n",
    "        c += 1\n",
    "        author_end = author_beg + c\n",
    "    author = raw_text[author_beg : author_end]\n",
    "    \n",
    "    book_author_mapping[label] = [title, author]\n",
    "    \n",
    "    return label, title, author\n",
    "\n",
    "#getting the author name, book name, labels\n",
    "label, author, title = [], [], []\n",
    "for i in range(len(raw_dataset)):\n",
    "    label_temp, title_temp, author_temp = extract_book_author(raw_dataset[i],i)\n",
    "    label.append(label_temp)\n",
    "    author.append(author_temp)\n",
    "    title.append(title_temp)\n",
    "    \n",
    "print(len(label))\n",
    "print(len(author))\n",
    "print(len(title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3a52a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to partition data\n",
    "def partitioned_text(tokens, title, author, label):\n",
    "    final_book_partitions = []\n",
    "    book_partitions = []\n",
    "    for j in range(len(tokens)):\n",
    "        subtractor = len(tokens[j])\n",
    "        for i in range(0, 200):\n",
    "            if(subtractor > 150):\n",
    "                partition = [\" \".join(tokens[j][i : i + 150]), title[j], author[j], label[j]]\n",
    "                book_partitions.append(partition)\n",
    "                subtractor -= 150\n",
    "    return book_partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a15f696",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>partitions</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>institute chicago prof john f genung ph amhers...</td>\n",
       "      <td>The Art Of Writing &amp; Speaking The English Lang...</td>\n",
       "      <td>Sherwin Cody</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>various branch addition assistance teaching le...</td>\n",
       "      <td>Beeton's Book of Needlework</td>\n",
       "      <td>Isabella Beeton</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>effective english among people write advertise...</td>\n",
       "      <td>The Art Of Writing &amp; Speaking The English Lang...</td>\n",
       "      <td>Sherwin Cody</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>unpleasant enemy woman instinctively suspected...</td>\n",
       "      <td>Murder in the Gunroom</td>\n",
       "      <td>Henry Beam Piper</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>exception chapter iv pronunciation chapter v s...</td>\n",
       "      <td>The Art Of Writing &amp; Speaking The English Lang...</td>\n",
       "      <td>Sherwin Cody</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>name greek letter e g alpha centauri single gr...</td>\n",
       "      <td>The Astronomy of Milton's 'Paradise Lost'</td>\n",
       "      <td>Thomas Orchard</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>husband collection number people wanted collec...</td>\n",
       "      <td>Murder in the Gunroom</td>\n",
       "      <td>Henry Beam Piper</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>v season vi starry heaven vii starry heaven vi...</td>\n",
       "      <td>The Astronomy of Milton's 'Paradise Lost'</td>\n",
       "      <td>Thomas Orchard</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>material requisite pattern stated chancellor p...</td>\n",
       "      <td>Beeton's Book of Needlework</td>\n",
       "      <td>Isabella Beeton</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>writing speaking english language general intr...</td>\n",
       "      <td>The Art Of Writing &amp; Speaking The English Lang...</td>\n",
       "      <td>Sherwin Cody</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            partitions  \\\n",
       "99   institute chicago prof john f genung ph amhers...   \n",
       "513  various branch addition assistance teaching le...   \n",
       "184  effective english among people write advertise...   \n",
       "767  unpleasant enemy woman instinctively suspected...   \n",
       "144  exception chapter iv pronunciation chapter v s...   \n",
       "..                                                 ...   \n",
       "239  name greek letter e g alpha centauri single gr...   \n",
       "696  husband collection number people wanted collec...   \n",
       "368  v season vi starry heaven vii starry heaven vi...   \n",
       "458  material requisite pattern stated chancellor p...   \n",
       "115  writing speaking english language general intr...   \n",
       "\n",
       "                                                 title            author label  \n",
       "99   The Art Of Writing & Speaking The English Lang...      Sherwin Cody     a  \n",
       "513                        Beeton's Book of Needlework   Isabella Beeton     c  \n",
       "184  The Art Of Writing & Speaking The English Lang...      Sherwin Cody     a  \n",
       "767                              Murder in the Gunroom  Henry Beam Piper     d  \n",
       "144  The Art Of Writing & Speaking The English Lang...      Sherwin Cody     a  \n",
       "..                                                 ...               ...   ...  \n",
       "239          The Astronomy of Milton's 'Paradise Lost'    Thomas Orchard     b  \n",
       "696                              Murder in the Gunroom  Henry Beam Piper     d  \n",
       "368          The Astronomy of Milton's 'Paradise Lost'    Thomas Orchard     b  \n",
       "458                        Beeton's Book of Needlework   Isabella Beeton     c  \n",
       "115  The Art Of Writing & Speaking The English Lang...      Sherwin Cody     a  \n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting partitoins\n",
    "partitions = pd.DataFrame(partitioned_text(tokens, title, author, label),columns = ['partitions', 'title', 'author', 'label'])\n",
    "\n",
    "partitions = shuffle(partitions)\n",
    "partitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185e4cd1",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba7f46a",
   "metadata": {},
   "source": [
    "## BOW model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adfe9b72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abdegilns</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>absurd</th>\n",
       "      <th>accident</th>\n",
       "      <th>according</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>acid</th>\n",
       "      <th>acknowledged</th>\n",
       "      <th>action</th>\n",
       "      <th>...</th>\n",
       "      <th>write</th>\n",
       "      <th>writer</th>\n",
       "      <th>writing</th>\n",
       "      <th>wrong</th>\n",
       "      <th>wrought</th>\n",
       "      <th>www</th>\n",
       "      <th>year</th>\n",
       "      <th>yet</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 1041 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     abdegilns  ability  able  absurd  accident  according  accuracy  acid  \\\n",
       "0            0        0     0       0         0          0         0     0   \n",
       "1            0        0     0       0         0          0         0     0   \n",
       "2            0        0     0       0         0          0         0     1   \n",
       "3            0        1     0       1         0          0         0     0   \n",
       "4            0        0     0       0         0          0         0     0   \n",
       "..         ...      ...   ...     ...       ...        ...       ...   ...   \n",
       "995          0        0     0       0         0          0         0     0   \n",
       "996          0        0     0       0         0          0         0     0   \n",
       "997          0        0     1       0         0          0         0     0   \n",
       "998          0        0     0       0         0          0         0     0   \n",
       "999          0        0     0       0         0          0         0     0   \n",
       "\n",
       "     acknowledged  action  ...  write  writer  writing  wrong  wrought  www  \\\n",
       "0               1       0  ...      2       0        3      0        0    0   \n",
       "1               0       0  ...      0       0        0      0        0    0   \n",
       "2               1       0  ...      2       0        0      0        0    0   \n",
       "3               0       0  ...      0       0        0      0        0    0   \n",
       "4               1       0  ...      2       0        2      0        0    0   \n",
       "..            ...     ...  ...    ...     ...      ...    ...      ...  ...   \n",
       "995             0       0  ...      0       0        0      0        0    0   \n",
       "996             0       0  ...      0       0        0      0        0    0   \n",
       "997             0       0  ...      0       2        0      0        0    0   \n",
       "998             0       0  ...      0       0        0      0        0    0   \n",
       "999             1       0  ...      2       0        3      0        0    0   \n",
       "\n",
       "     year  yet  york  young  \n",
       "0       0    1     0      0  \n",
       "1       1    0     0      0  \n",
       "2       0    1     0      0  \n",
       "3       1    0     0      0  \n",
       "4       0    1     0      0  \n",
       "..    ...  ...   ...    ...  \n",
       "995     0    0     1      0  \n",
       "996     1    0     0      0  \n",
       "997     0    0     0      1  \n",
       "998     0    0     0      0  \n",
       "999     0    1     0      0  \n",
       "\n",
       "[1000 rows x 1041 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def model_BOW(data): # take the partitions\n",
    "    cv = CountVectorizer()\n",
    "    cv_fit = cv.fit_transform(data.iloc[:,0]).toarray()\n",
    "    cv_fit_df = pd.DataFrame(cv_fit, columns = cv.get_feature_names())\n",
    "    return cv_fit_df\n",
    "    \n",
    "\n",
    "bow_vectorizer = model_BOW(partitions)\n",
    "bow_vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0e3127",
   "metadata": {},
   "source": [
    "## TF-IDF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ca64eeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abdegilns</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>absurd</th>\n",
       "      <th>accident</th>\n",
       "      <th>according</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>acid</th>\n",
       "      <th>acknowledged</th>\n",
       "      <th>action</th>\n",
       "      <th>...</th>\n",
       "      <th>write</th>\n",
       "      <th>writer</th>\n",
       "      <th>writing</th>\n",
       "      <th>wrong</th>\n",
       "      <th>wrought</th>\n",
       "      <th>www</th>\n",
       "      <th>year</th>\n",
       "      <th>yet</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.073503</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.135330</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200378</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.075470</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.050595</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.099572</td>\n",
       "      <td>0.065613</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.120804</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.067369</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.078006</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.087929</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.051115</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.073234</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.134834</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.133096</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.075194</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047504</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.057683</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.077761</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156412</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.095921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.072827</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.134085</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.198534</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.074776</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 1041 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     abdegilns   ability      able    absurd  accident  according  accuracy  \\\n",
       "0          0.0  0.000000  0.000000  0.000000       0.0        0.0       0.0   \n",
       "1          0.0  0.000000  0.000000  0.000000       0.0        0.0       0.0   \n",
       "2          0.0  0.000000  0.000000  0.000000       0.0        0.0       0.0   \n",
       "3          0.0  0.078006  0.000000  0.087929       0.0        0.0       0.0   \n",
       "4          0.0  0.000000  0.000000  0.000000       0.0        0.0       0.0   \n",
       "..         ...       ...       ...       ...       ...        ...       ...   \n",
       "995        0.0  0.000000  0.000000  0.000000       0.0        0.0       0.0   \n",
       "996        0.0  0.000000  0.000000  0.000000       0.0        0.0       0.0   \n",
       "997        0.0  0.000000  0.077761  0.000000       0.0        0.0       0.0   \n",
       "998        0.0  0.000000  0.000000  0.000000       0.0        0.0       0.0   \n",
       "999        0.0  0.000000  0.000000  0.000000       0.0        0.0       0.0   \n",
       "\n",
       "         acid  acknowledged  action  ...     write    writer   writing  wrong  \\\n",
       "0    0.000000      0.073503     0.0  ...  0.135330  0.000000  0.200378    0.0   \n",
       "1    0.000000      0.000000     0.0  ...  0.000000  0.000000  0.000000    0.0   \n",
       "2    0.099572      0.065613     0.0  ...  0.120804  0.000000  0.000000    0.0   \n",
       "3    0.000000      0.000000     0.0  ...  0.000000  0.000000  0.000000    0.0   \n",
       "4    0.000000      0.073234     0.0  ...  0.134834  0.000000  0.133096    0.0   \n",
       "..        ...           ...     ...  ...       ...       ...       ...    ...   \n",
       "995  0.000000      0.000000     0.0  ...  0.000000  0.000000  0.000000    0.0   \n",
       "996  0.000000      0.000000     0.0  ...  0.000000  0.000000  0.000000    0.0   \n",
       "997  0.000000      0.000000     0.0  ...  0.000000  0.156412  0.000000    0.0   \n",
       "998  0.000000      0.000000     0.0  ...  0.000000  0.000000  0.000000    0.0   \n",
       "999  0.000000      0.072827     0.0  ...  0.134085  0.000000  0.198534    0.0   \n",
       "\n",
       "     wrought  www      year       yet      york     young  \n",
       "0        0.0  0.0  0.000000  0.075470  0.000000  0.000000  \n",
       "1        0.0  0.0  0.050595  0.000000  0.000000  0.000000  \n",
       "2        0.0  0.0  0.000000  0.067369  0.000000  0.000000  \n",
       "3        0.0  0.0  0.051115  0.000000  0.000000  0.000000  \n",
       "4        0.0  0.0  0.000000  0.075194  0.000000  0.000000  \n",
       "..       ...  ...       ...       ...       ...       ...  \n",
       "995      0.0  0.0  0.000000  0.000000  0.047504  0.000000  \n",
       "996      0.0  0.0  0.057683  0.000000  0.000000  0.000000  \n",
       "997      0.0  0.0  0.000000  0.000000  0.000000  0.095921  \n",
       "998      0.0  0.0  0.000000  0.000000  0.000000  0.000000  \n",
       "999      0.0  0.0  0.000000  0.074776  0.000000  0.000000  \n",
       "\n",
       "[1000 rows x 1041 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def model_TFIDF(data): # take the partitions\n",
    "    tfIdf = TfidfVectorizer(use_idf=True)\n",
    "    tfidf_fit = tfIdf.fit_transform(data.iloc[:,0]).toarray()\n",
    "    tfidf_fit_df = pd.DataFrame(tfidf_fit, columns = tfIdf.get_feature_names())\n",
    "    return tfidf_fit_df\n",
    "\n",
    "tfidf_vectorizer = model_TFIDF(partitions)\n",
    "tfidf_vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5414a1",
   "metadata": {},
   "source": [
    "## LDA as a feature extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6314966f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00135697, 0.00135469, 0.00135506, 0.00135817, 0.99457511],\n",
       "       [0.00132722, 0.00132524, 0.00132523, 0.99469468, 0.00132763],\n",
       "       [0.00863815, 0.00139554, 0.00136063, 0.10347662, 0.88512907],\n",
       "       ...,\n",
       "       [0.00138226, 0.00138097, 0.00138259, 0.00139157, 0.99446261],\n",
       "       [0.0013348 , 0.00133437, 0.00133488, 0.99465918, 0.00133678],\n",
       "       [0.00135768, 0.00135432, 0.00135424, 0.00135705, 0.99457673]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def model_LDA2(data): # take the partitions\n",
    "    cv = CountVectorizer(max_df = 0.9, min_df = 2)\n",
    "    dtm = cv.fit_transform(data)\n",
    "    lda = LatentDirichletAllocation(n_components = 5, random_state = 5)\n",
    "    lda = lda.fit_transform(dtm)\n",
    "    return lda\n",
    "\n",
    "lda = model_LDA2(partitions['partitions'])\n",
    "lda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c82ceda",
   "metadata": {},
   "source": [
    "## wordembedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ca23c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "partitions_splitted = []\n",
    "for partition in partitions['partitions']:\n",
    "    temp = partition.split()\n",
    "    partitions_splitted.append(temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1cb88cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_word2vec(tokens_data): # take the partitions_splitted\n",
    "    model = Word2Vec(sentences = tokens_data, vector_size = 150, workers = 6)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ffde4c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.word2vec.Word2Vec at 0x1f928b88eb0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_model = model_word2vec(partitions_splitted)\n",
    "word2vec_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0879b3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the word document vectors\n",
    "def doc_vectors(data_tokens, word2vec_model):\n",
    "    features = []\n",
    "    for tokens in data_tokens:\n",
    "        zero_vector = np.zeros(word2vec_model.vector_size)\n",
    "        vectors = []\n",
    "        for token in tokens:\n",
    "            if token in word2vec_model.wv:\n",
    "                vectors.append(word2vec_model.wv[token])\n",
    "        if vectors:\n",
    "            vectors = np.asarray(vectors)\n",
    "            avg_vec = vectors.mean(axis = 0)\n",
    "            features.append(avg_vec)\n",
    "        else:\n",
    "            features.append(zero_vector)\n",
    "    return features\n",
    "\n",
    "vectorized_doc = doc_vectors(partitions_splitted, word2vec_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e41286f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 150)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorized_doc), len(vectorized_doc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa31e50",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78ea066",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
