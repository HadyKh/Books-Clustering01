{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7534de59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hadyo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hadyo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\hadyo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore', category = DeprecationWarning)\n",
    "import requests\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from urllib import request\n",
    "from random import randint\n",
    "#from wordcloud import WordCloud\n",
    "from nltk import word_tokenize\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import gensim\n",
    "from gensim.models import LdaModel, Word2Vec\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn import preprocessing\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "#!pip install mlxtend\n",
    "#from mlxtend.evaluate import bias_variance_decomp\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection  import cross_val_score\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, confusion_matrix, plot_confusion_matrix\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2111929b",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_url_list = [\"https://www.gutenberg.org/files/19719/19719-0.txt\",\n",
    "                  \"https://www.gutenberg.org/cache/epub/28434/pg28434.txt\",\n",
    "                  \"https://www.gutenberg.org/cache/epub/15147/pg15147.txt\",\n",
    "                  \"https://www.gutenberg.org/cache/epub/17866/pg17866.txt\",\n",
    "                  \"https://www.gutenberg.org/files/3772/3772-0.txt\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccffe308",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81fb2497",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#function read raw data\n",
    "def read_books(url):\n",
    "    files = []\n",
    "    for i in url:\n",
    "        file = requests.get(url = i)\n",
    "        files.append(file.content.decode('utf-8'))\n",
    "    return files\n",
    "\n",
    "#read raw data\n",
    "raw_dataset = read_books(books_url_list)\n",
    "len(raw_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92462147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Function cleaned tokens\n",
    "def cleaned_text(raw_text):\n",
    "    text_beg = raw_text.find(\"*** START OF\")\n",
    "    text_end = raw_text.find(\"*** END OF\")\n",
    "\n",
    "    raw_text = raw_text[text_beg : text_end]\n",
    "    raw_text = re.findall(r\"[a-zA-Z]+\", raw_text)\n",
    "    raw_text = \" \".join(raw_text).lower()\n",
    "    tokens = word_tokenize(raw_text)\n",
    "    stop_words = stopwords.words(\"english\")\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens if token not in stop_words]\n",
    "    \n",
    "    return tokens\n",
    "#Getting cleaned tokens\n",
    "tokens = []\n",
    "for i in range(len(raw_dataset)):\n",
    "    tokens.append(cleaned_text(raw_dataset[i]))\n",
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5009246c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "5\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "#function to extract author name, book name and labels\n",
    "book_author_mapping = {}\n",
    "def extract_book_author(raw_text, index):\n",
    "    label = chr(index + 97)\n",
    "        \n",
    "    title_beg = raw_text.find(\"Title\") + 7\n",
    "    title_end = raw_text.find(\"\\r\\n\\r\\nAuthor\")\n",
    "    title = raw_text[title_beg : title_end]\n",
    "\n",
    "    author_beg = raw_text.find(\"Author\") + 8\n",
    "    c = 0\n",
    "    while raw_text[author_beg + c] != \"\\r\":\n",
    "        c += 1\n",
    "        author_end = author_beg + c\n",
    "    author = raw_text[author_beg : author_end]\n",
    "    \n",
    "    book_author_mapping[label] = [title, author]\n",
    "    \n",
    "    return label, title, author\n",
    "\n",
    "#getting the author name, book name, labels\n",
    "label, author, title = [], [], []\n",
    "for i in range(len(raw_dataset)):\n",
    "    label_temp, title_temp, author_temp = extract_book_author(raw_dataset[i],i)\n",
    "    label.append(label_temp)\n",
    "    author.append(author_temp)\n",
    "    title.append(title_temp)\n",
    "    \n",
    "print(len(label))\n",
    "print(len(author))\n",
    "print(len(title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e01f3b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to partition data\n",
    "def partitioned_text(tokens, title, author, label):\n",
    "    final_book_partitions = []\n",
    "    book_partitions = []\n",
    "    for j in range(len(tokens)):\n",
    "        subtractor = len(tokens[j])\n",
    "        for i in range(0, 200):\n",
    "            if(subtractor > 150):\n",
    "                partition = [\" \".join(tokens[j][i : i + 150]), title[j], author[j], label[j]]\n",
    "                book_partitions.append(partition)\n",
    "                subtractor -= 150\n",
    "    return book_partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3a25b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>partitions</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>murder gunroom produced greg week mary meehan ...</td>\n",
       "      <td>Murder in the Gunroom</td>\n",
       "      <td>Henry Beam Piper</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>glorious work parent good almighty thine unive...</td>\n",
       "      <td>The Astronomy of Milton's 'Paradise Lost'</td>\n",
       "      <td>Thomas Orchard</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>czechoslovakia samuel butler preface art needl...</td>\n",
       "      <td>Beeton's Book of Needlework</td>\n",
       "      <td>Isabella Beeton</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>barkley pg online distributed proofreading tea...</td>\n",
       "      <td>Beeton's Book of Needlework</td>\n",
       "      <td>Isabella Beeton</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771</th>\n",
       "      <td>suspected would make satisfying lover one migh...</td>\n",
       "      <td>Murder in the Gunroom</td>\n",
       "      <td>Henry Beam Piper</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>serviceable friend particularly unpleasant ene...</td>\n",
       "      <td>Murder in the Gunroom</td>\n",
       "      <td>Henry Beam Piper</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>york alfred knopf first edition colonel henry ...</td>\n",
       "      <td>Murder in the Gunroom</td>\n",
       "      <td>Henry Beam Piper</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>berlin wool work point lace guipure art prefix...</td>\n",
       "      <td>Beeton's Book of Needlework</td>\n",
       "      <td>Isabella Beeton</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>p consequenc changed consequence p geographiea...</td>\n",
       "      <td>The Astronomy of Milton's 'Paradise Lost'</td>\n",
       "      <td>Thomas Orchard</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>colt type percussion revolver hand coroner ver...</td>\n",
       "      <td>Murder in the Gunroom</td>\n",
       "      <td>Henry Beam Piper</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            partitions  \\\n",
       "604  murder gunroom produced greg week mary meehan ...   \n",
       "327  glorious work parent good almighty thine unive...   \n",
       "486  czechoslovakia samuel butler preface art needl...   \n",
       "409  barkley pg online distributed proofreading tea...   \n",
       "771  suspected would make satisfying lover one migh...   \n",
       "..                                                 ...   \n",
       "764  serviceable friend particularly unpleasant ene...   \n",
       "625  york alfred knopf first edition colonel henry ...   \n",
       "581  berlin wool work point lace guipure art prefix...   \n",
       "286  p consequenc changed consequence p geographiea...   \n",
       "665  colt type percussion revolver hand coroner ver...   \n",
       "\n",
       "                                         title            author label  \n",
       "604                      Murder in the Gunroom  Henry Beam Piper     d  \n",
       "327  The Astronomy of Milton's 'Paradise Lost'    Thomas Orchard     b  \n",
       "486                Beeton's Book of Needlework   Isabella Beeton     c  \n",
       "409                Beeton's Book of Needlework   Isabella Beeton     c  \n",
       "771                      Murder in the Gunroom  Henry Beam Piper     d  \n",
       "..                                         ...               ...   ...  \n",
       "764                      Murder in the Gunroom  Henry Beam Piper     d  \n",
       "625                      Murder in the Gunroom  Henry Beam Piper     d  \n",
       "581                Beeton's Book of Needlework   Isabella Beeton     c  \n",
       "286  The Astronomy of Milton's 'Paradise Lost'    Thomas Orchard     b  \n",
       "665                      Murder in the Gunroom  Henry Beam Piper     d  \n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting partitoins\n",
    "partitions = pd.DataFrame(partitioned_text(tokens, title, author, label),columns = ['partitions', 'title', 'author', 'label'])\n",
    "\n",
    "partitions = shuffle(partitions)\n",
    "partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413e43d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
